\documentclass[a4paper,twoside]{article}

\usepackage{epsfig}
\usepackage{subfigure}
\usepackage{calc}
\usepackage{amssymb}
\usepackage{amstext}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{multicol}
\usepackage{pslatex}
\usepackage{apalike}
\usepackage{SCITEPRESS}     % Please add other packages that you may need BEFORE the SCITEPRESS.sty package.

\subfigtopskip=0pt
\subfigcapskip=0pt
\subfigbottomskip=0pt

\begin{document}


\title{GPU Virtualization in the Cloud (a mejorar el t\'itulo!!!)}
\author{\authorname{Sergio Iserte, Francisco J. Clemente-Castell\'o, Adri\'an Castell\'o,\\Rafael Mayo and Enrique S. Quintana-Ort\'i}
\affiliation{Department of Computer Science and Engineering\\Universitat Jaume I - Castell\'o de la Plana, Spain}
\email{\{siserte, fclement, adcastel, mayo, quintana\}@uji.es}}

\keywords{The paper must have at least one keyword. The text must be set to 9-point font size and without the use of bold or italic font style. For more than one keyword, please use a comma as a separator. Keywords must be titlecased.}

\abstract{The abstract should summarize the contents of the paper and should contain at least 70 and at most 200 words. The text must be set to 9-point font size.}

\onecolumn \maketitle \normalsize \vfill

\section{\uppercase{Introduction}}
\label{sec:introduction}

\noindent Your paper will be part of the conference proceedings
therefore we ask that authors follow the guidelines explained in
this example in order to achieve the highest quality possible
\cite{Smith98}.

Be advised that papers in a technically unsuitable form will be
returned for retyping. After returned the manuscript must be
appropriately modified.

\section{\uppercase{Background}}
\label{sec:background}
\subsection{The rCUDA Framework}
\label{sec:rcuda}

{rCUDA}~\cite{tonithesis,toniparco} is a middleware that enables transparent access
to any NVIDIA GPU device present in a cluster from all compute
nodes. The GPUs can be accessed and shared between nodes, and a single node can use all these graphic accelerators
as if they were local.
These features are focused in attaining higher accelerator utilization rates in the overall system while simultaneously reducing
resource, space, and energy~\cite{energy14} requirements.
rCUDA is structured following a client-server distributed
architecture: the client middleware is allocated in the same cluster node where the application demanding GPGPU
acceleration services is executed, providing a transparent replacement for the
native CUDA libraries. Furthermore, the server middleware is executed in the
cluster nodes from which the actual GPUs provide the requested GPGPU service.
To support a concurrent scenario where GPUs are shared between
processes\slash nodes, {rCUDA} manages separate device contexts for
each client application.

The {rCUDA} 5.0 client exposes the same interface as the regular NVIDIA
CUDA 6.5 release~\cite{cuda65}, including the runtime and driver
APIs as well as other commonly used libraries such as cuBLAS, cuFFT, cuSparse or cuRand.
Therefore, applications are not aware of the fact that they are being executed
on top of a virtualization layer.
With the aim to be updated with new GPU programming models, {rCUDA} also supports
directive-based models such as OmpSS~\cite{repara15} and OpenACC~\cite{cluster15}.

The integration of remote GPGPU virtualization with global
resource schedulers such as SLURM~\cite{sbacpad14} completes this powerful
technology, making accelerator-enabled clusters more flexible and
energy efficient.

\subsection{Manuscript Setup}


\subsection{Page Setup}


\section*{\uppercase{Acknowledgements}}

\bibliographystyle{apalike}
{\small
\bibliography{paper}}


\end{document}

